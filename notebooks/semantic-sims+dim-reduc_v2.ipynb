{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I4tj7gO-naB"
      },
      "source": [
        "# Semantics Similarity\n",
        "This notebook generates multiple representations of the difference in semantic similarity between two datasets.\n",
        "\n",
        "More specifically, it was designed to probe the semantic difference between specific categories of TruthfulQA and custom datasets created as *holdouts* for those categories.\n",
        "\n",
        "The two methods are:\n",
        "1. [Uniform Manifold Approximation and Projection](https://umap-learn.readthedocs.io/en/latest/index.html) (UMAP) to reduce dimensionality of embeddings and plot a visual representation. This is used as a sanity check; if we can percieve clear differences in the visual representation of the our `retro` and the `target`, our other test should probably pick up on these differences as well.\n",
        "2. This one is slightly more complicated, but allows for a concrete p-value, and has shown to be more sensitive to differences than more straight forward methods, such as simply comparing mean cosine similarity.\n",
        "    - First, we randomly sample the `combined` datasets for some numer of entries `s`; we designate the `i`th sampling `pulls[i]`. Note that `s` cannot be larger than the smallest of the two input datasets.\n",
        "    - We then calculate the unique, nontrivial cosine similarities between `pulls[i]` and `combined`.\n",
        "        - This excludes two types of entries: when an embedding is compared with itself, and when an embedding has already been compared (i.e., we do not compare AðŸ –B when we already have calculated BðŸ –A)\n",
        "    - Leverage the [Anderson Darling k-sample test](https://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/andeksam.htm) (ADk) to create a *likelihood of same distribution* value for each sample, `pulls[i]`, when compared to the *combined dataset*.\n",
        "        - This can be written `ADk_test_statistic(cos_sim(combined), cos_sim(pulls[i]))`.\n",
        "    - We then use ADk to compare `combined` and `retro` in the same manner.\n",
        "    - Finally, we calculate the likelihood that an ADk test statistic greater than the value seen when comparing `combined` and `retro` could be produced by replacing `retro` with a random sample.\n",
        "        - If this is very likely (>95%) or very unlikely (<5%), we say that the datasets are not sufficiently similar, according to this test.\n",
        "\n",
        "\n",
        "When run in Colab using free instances it takes ~5 minutes to run in its entirety."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWsGdzfxn0bA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  !git clone https://github.com/cwenner/retrospective-llm-eval.git\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  import os\n",
        "  import sys\n",
        "  sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV5tDM6LpcYU"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install datasets==2.15.0\n",
        "!pip install scipy\n",
        "!pip install umap-learn\n",
        "!pip install umap-learn[plot]\n",
        "!pip install umap-learn[parametric_umap]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbYUK-SZoTyl"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import sentence_transformers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import umap\n",
        "import seaborn as sns\n",
        "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwLcI7-LGnrv"
      },
      "source": [
        "# Prep\n",
        "- Set user defined variables\n",
        "- Choose our embedding model\n",
        "- Create helper functions to load our datasets\n",
        "- Create helper functions to generate the embeddings for our  datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOVp_Aa_7HfS"
      },
      "outputs": [],
      "source": [
        "# DATASET_FILENAME = \"crafted_dataset_unfiltered.jsonl\"\n",
        "DATASET_FILENAME = \"crafted_nora+vasco_v1-gram.csv\"\n",
        "VERBOSE: bool = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAWpwQzYKt4u"
      },
      "source": [
        "#### Choose Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxyQa8a9JFrM"
      },
      "outputs": [],
      "source": [
        "embedding_model = sentence_transformers.SentenceTransformer(\n",
        "    \"all-mpnet-base-v2\", device=\"cpu\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl_WrfGLKzGf"
      },
      "source": [
        "#### Helper Functions: Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzkaXG4wKp6d"
      },
      "outputs": [],
      "source": [
        "# Encode a string using the chosen embedding model\n",
        "    # NOTE: this action is described by the verb \"to embed\" in rest of notebook\n",
        "def embed(text: str) -> np.array:\n",
        "    return embedding_model.encode(text, convert_to_tensor=True).numpy() # @Cenny, why don't we use this function later in the \"get_embed_mat\" function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubfjd6E9IAw4"
      },
      "outputs": [],
      "source": [
        "def get_embed_mat(\n",
        "    dataset_to_embed: datasets.Dataset,\n",
        "    exclude_choices: bool = False,\n",
        ") -> np.array:\n",
        "    \"\"\"\n",
        "    Embed elements from a dataset that uses the TruthfulQA structure.\n",
        "\n",
        "    Args:\n",
        "        truthfulqa_dataset (datasets.Dataset): The dataset to embed.\n",
        "        exclude_choices (bool, optional): If this is True, only the\n",
        "            questions will be embedded. If this is False, the questions\n",
        "            and choices will be embedded. Defaults to False.\n",
        "    \"\"\"\n",
        "    if exclude_choices:\n",
        "        texts = dataset_to_embed[\"question\"]\n",
        "    else:\n",
        "        texts = [\n",
        "            # \"\\n\".join([x[\"question\"]] + x[\"mc1_targets\"][\"choices\"])\n",
        "            \"\\n\".join([x[\"question\"]] + sorted(x[\"mc1_targets\"][\"choices\"]))\n",
        "            for x in dataset_to_embed\n",
        "        ]\n",
        "\n",
        "    if VERBOSE: list(map(lambda i: print(f'{i}\\n{texts[i]}\\n'), np.random.choice(len(texts),2)))\n",
        "\n",
        "    return embedding_model.encode(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEmrCNqHK3xw"
      },
      "source": [
        "#### Helper Functions: Datasets Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W60Z6LLjKnSM"
      },
      "outputs": [],
      "source": [
        "# The HuggingFace (HF) TruthfulQA (TQA) dataset only has category labels in the\n",
        "#   \"generation\" task version, but we also need the possible answers that are\n",
        "#   found in the \"multiple_choice\" version. This function uses the categories\n",
        "#   defined in the \"generation\" version to filter the \"multiple_choice\" version\n",
        "    # NOTE: This probably isn't necessary for most other datasets\n",
        "def load_truthfulqa(category=None):\n",
        "    ds = datasets.load_dataset(\"truthful_qa\", \"multiple_choice\")[\"validation\"]\n",
        "    if category and category != \"all\":\n",
        "        filtered_ds = datasets.load_dataset(\"truthful_qa\", \"generation\")\n",
        "        filtered_ds = filtered_ds.filter(\n",
        "            lambda x: x[\"category\"].lower() == category.lower()\n",
        "        )\n",
        "        filtered_questions = filtered_ds[\"validation\"][\"question\"]\n",
        "        ds = ds.filter(lambda x: x[\"question\"] in filtered_questions)\n",
        "        if VERBOSE: print(f'TruthfulQA category loaded: {category}')\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L8NZBn58IeF"
      },
      "outputs": [],
      "source": [
        "def custom_loader(ds):\n",
        "    # Splits string by \".\" and sets 'ext' to the final substring;\n",
        "    #   this is effectively the same a taking the file's extension\n",
        "    *f, ext = DATASET_FILENAME.split(\".\")\n",
        "    ext = ext.lower()\n",
        "\n",
        "    # Switch statement for csv and json/jsonl files\n",
        "    #   csv files need added logic to put them into the HF dataset format\n",
        "    if ext == 'csv':\n",
        "        def array(x, dtype=None):\n",
        "            return x\n",
        "\n",
        "        # Special logic due to how the CSV stores choices as a string\n",
        "        import_ds = datasets.load_dataset(\n",
        "            \"csv\", data_files=f'retrospective-llm-eval/data/datasets/{ds}'\n",
        "        )[\"train\"]\n",
        "\n",
        "        import_ds = import_ds.map(\n",
        "            lambda x: {\n",
        "                \"question\": x[\"question\"],\n",
        "                \"mc1_targets\": eval(x[\"mc1_targets\"], dict(globals(), array=array), locals()),\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # import_ds = import_ds.map(lambda x:\n",
        "        #     dict(\n",
        "        #         question=x[\"Rewritten in style\"],\n",
        "        #         mc1_targets=dict(\n",
        "        #             choices=[\n",
        "        #                 x\n",
        "        #                 for x in [\n",
        "        #                         x[\"Correct\"],\n",
        "        #                 ] + [\n",
        "        #                     x[f\"Incorrect{i}\"]\n",
        "        #                     for i in range(1, 11)\n",
        "        #                 ]\n",
        "        #                 if x\n",
        "        #             ]\n",
        "        #         )\n",
        "        #     ),\n",
        "        #     remove_columns=import_ds.column_names\n",
        "        # )\n",
        "    elif ext == 'jsonl'or ext == 'json':\n",
        "        import_ds = datasets.load_dataset(\n",
        "            \"json\", data_files=f'retrospective-llm-eval/data/datasets/{ds}'\n",
        "        )[\"train\"]\n",
        "    return import_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions: Write to Logfile"
      ],
      "metadata": {
        "id": "0US2hBKzENaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logfile_write(dataset_filename, content):\n",
        "    *f, ext = dataset_filename.split(\".\")\n",
        "    logfile = open(f'{f[0]}.txt','a')\n",
        "    logfile.writelines(content)\n",
        "    logfile.write('\\n')\n",
        "    logfile.close()"
      ],
      "metadata": {
        "id": "i4g43cC_F2PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ZPgx_pMSzu"
      },
      "source": [
        "# Get Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets\n",
        "``` load_truthfulqa ``` has special logic for only pulling specific categories of the dataset\n",
        "\n",
        "``` custom_loader ``` can handle {.json; .jsonl; .csv}"
      ],
      "metadata": {
        "id": "GszURAm65YjZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZBbuwI4Lcng"
      },
      "outputs": [],
      "source": [
        "# target_ds = load_truthfulqa(\"misconceptions\")\n",
        "\n",
        "target_ds = load_truthfulqa(\"misconceptions\")\n",
        "retro_ds = custom_loader(DATASET_FILENAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzo5RvsUMppW"
      },
      "source": [
        "## Caculate embeddings\n",
        "Embeddings are calculated for the entire dataset entry, including both question and potential responses. Additional prompting (scaffolding) is not included in this embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy9aQ6UQMN4C"
      },
      "outputs": [],
      "source": [
        "# Get embeddings for both the target and retro datasets\n",
        "target_embs = get_embed_mat(target_ds)\n",
        "retro_embs = get_embed_mat(retro_ds)\n",
        "num_entries = [embs.shape[0] for embs in [target_ds, retro_ds]]\n",
        "if VERBOSE: print(f'Entries in target = {num_entries[0]}\\nEntries in retro  = {num_entries[1]}\\n')\n",
        "\n",
        "# Stack the two matrices of embedded entries on top of eachother\n",
        "combined_embs = np.concatenate((target_embs, retro_embs), axis = 0)\n",
        "if VERBOSE: print(f'Shape of embedded combined datasets = {combined_embs.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UMAP"
      ],
      "metadata": {
        "id": "yiAUw3GPnym-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up UMAP\n",
        "reducer = umap.UMAP()\n",
        "scaled_embs = StandardScaler().fit_transform(combined_embs)\n",
        "umapped = reducer.fit_transform(scaled_embs)"
      ],
      "metadata": {
        "id": "CnfOXwP_bAVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results of UMAP\n",
        "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
        "\n",
        "ax.scatter(umapped[:num_entries[0], 0],umapped[:num_entries[0], 1])\n",
        "ax.scatter(umapped[num_entries[0]:, 0],umapped[num_entries[0]:, 1])\n",
        "# ax.scatter(umapped[num_entries[0]:num_entries[0]+num_entries[1]-1, 0],umapped[num_entries[0]:num_entries[0]+num_entries[1]-1, 1])\n",
        "# ax.scatter(umapped[num_entries[0]+num_entries[1]:, 0],umapped[num_entries[0]+num_entries[1]:, 1])\n",
        "ax.legend(['Target', 'Retro'])\n",
        "ax.set_aspect('equal', 'datalim')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nzr9EWOsemYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Original Semantics Similarity Test"
      ],
      "metadata": {
        "id": "xbesUFsNpUhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions: Cosine Similarity"
      ],
      "metadata": {
        "id": "gJhGSDoBpdjo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB3lQsrV_XJn"
      },
      "outputs": [],
      "source": [
        "def self_sim_mat(embs: np.array) -> float:\n",
        "    # INPUT: NxA matrix of N embbeddings; each row is a different prompt\n",
        "    # OUTPUT: NxN masked matrix w/ the diagonal & upper diagonal masked;\n",
        "        # each row (i) is the cosine similarity between the\n",
        "        # (i)th embedding and each (other) embedding in the input matrix;\n",
        "        # the entry corresponding to cosine similarity with itself is masked\n",
        "    sims = sentence_transformers.util.cos_sim(embs, embs).numpy()\n",
        "    mask = np.tril(np.ones(sims.shape[0]),0)\n",
        "    return np.ma.masked_array(sims,mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WySL3n5OGdTk"
      },
      "outputs": [],
      "source": [
        "def cross_sim_vec(embs1: np.array, embs2: np.array) -> float:\n",
        "    # INPUT:\n",
        "        # embs1 ~ NxA matrix of N embbeddings; each row is a different prompt\n",
        "        # embs2 ~ MxA matrix of M embbeddings; each row is a different prompt\n",
        "    # OUTPUT: N*Mx1 vector which is the 1-dimensional representation of the\n",
        "        # cosine similarities between embeddings (rows) in embs1 and embs2;\n",
        "        # note that sims is an NxM matrix representation\n",
        "    sims = sentence_transformers.util.cos_sim(embs1, embs2).numpy()\n",
        "    return sims.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_pull(embs: np.array, samp_size: int, num_samples: int):\n",
        "    # INPUTS:\n",
        "        # embs ~ NxA matrix of N embbeddings; each row is a different prompt\n",
        "        # samp_size ~ the number of rows to draw for each sample (dimension 2 of output matrix)\n",
        "        # num_samples ~ number of samples to take (dimension 1 of output matrix)\n",
        "    # OUTPUT 1: (num_samples)x(samp_size)x(embs.shape[1]);\n",
        "        # each layer (constant value in dimension 1) is a set of embeddings for\n",
        "        # (sample_size) random entries\n",
        "    # OUTPUT 2: (num_samples)x(NUM REMAINING ENTRIES)x(embs.shape[1]);\n",
        "        # each layer (constant value in dimension 1) is a set of embeddings for\n",
        "        # the remaining entries in Combined\n",
        "    pulls = np.ma.zeros((num_samples, samp_size, embs.shape[1]),dtype='float32')\n",
        "    lefts = np.ma.zeros((num_samples, abs(samp_size-embs.shape[0]), embs.shape[1]),dtype='float32')\n",
        "    for i in range(num_samples):\n",
        "        np.random.shuffle(embs)\n",
        "        pulls[i] = embs[:samp_size,:]\n",
        "        lefts[i] = embs[samp_size:,:]\n",
        "    return pulls, lefts"
      ],
      "metadata": {
        "id": "iUunWllHEc3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precompute All Cosine Similarities"
      ],
      "metadata": {
        "id": "t4yBuYeupraG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK63YqfL-gpM"
      },
      "outputs": [],
      "source": [
        "# Calculate the self similarities of the combined dataset\n",
        "    # NOTE: We mask the diagonal because these entries represent comparing an\n",
        "    #   embedding with itself; we also mask the upper triangle because it is a\n",
        "    #   mirror of the values in the lower triangle.\n",
        "combined_cos_sim = self_sim_mat(combined_embs).compressed()\n",
        "entry_count = sum(num_entries)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anderson Darling k-Sample Test"
      ],
      "metadata": {
        "id": "-ECDIMXhp7_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Precompute all sub-samples"
      ],
      "metadata": {
        "id": "XCsSbaXkqCBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples (layers of the final matrix; times to run the AK test)\n",
        "N = 25000\n",
        "\n",
        "# Sample size of each layer (number of entries to pull for each sample)\n",
        "s = min(num_entries)\n",
        "\n",
        "# Actually generate the stack\n",
        "pull_stack, left_stack = shuffle_pull(combined_embs, s, N)\n",
        "\n",
        "# Print info\n",
        "if VERBOSE: print(f'Number of times to run AK test = {N}\\nNumber of samples per AK test = {s}')"
      ],
      "metadata": {
        "id": "eVlqfGhcTivA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate AK statistics\n",
        "For each sample, calculate AK statistic for whether the cosine similarities between the sample and the target could have been pulled from the same distribution as the cosine similarities of the combined embeddings.\n",
        "\n",
        "For each sample, calculate AK statistic for whether the cosine similarities between the sample and itself could have been pulled from the same distribution as the cosine similarities of the combined embeddings."
      ],
      "metadata": {
        "id": "cvAVudjNqLBo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0a_fTt5Utn1"
      },
      "outputs": [],
      "source": [
        "# Calculate the AK test statistic for determining whether each random sampling of\n",
        "# embeddings could have been pulled from the distribution in the COMBINED dataset\n",
        "    # shorthand: random_samples(COMBINED,len(RETRO))ðŸ –COMBINED\n",
        "ak_stats = np.zeros(N,)\n",
        "for i in range(N):\n",
        "    ak_stats[i] = sp.stats.anderson_ksamp([combined_cos_sim,\n",
        "                                           np.concatenate((cross_sim_vec(left_stack[i], pull_stack[i]),\n",
        "                                                           self_sim_mat(pull_stack[i]).compressed()))]).statistic\n",
        "\n",
        "# # One-line version, doesn't seem to speed up anything though :/\n",
        "# ak_stats = list(map(lambda i: sp.stats.anderson_ksamp([combined_cos_sim, np.concatenate((cross_sim_vec(left_stack[i], pull_stack[i]), self_sim_mat(pull_stack[i]).compressed()))]).statistic]).statistic, range(N)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of self-similarity distribution\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pjtuoxuob0to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(self_sim_mat(retro_embs).compressed(), bins=np.arange(-0.1, 1.0, 0.1), alpha=0.5, density=True, color='blue')\n",
        "plt.hist(self_sim_mat(target_embs[:retro_embs.shape[0],:]).compressed(), bins=np.arange(-0.1, 1.0, 0.1), alpha=0.5, density=True,color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vd14eYgdVZIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_show = 10\n",
        "print(\"Most similar pairs in each dataset:\")\n",
        "for ds_name, ds, embs_set in [(\"target\", target_ds, target_embs), (\"retro\", retro_ds, retro_embs)]:\n",
        "  print(f\"Dataset: {ds_name}\")\n",
        "  # Compare sets of the same size\n",
        "  embs_set = embs_set[:retro_embs.shape[0],:]\n",
        "\n",
        "  self_sims_set = self_sim_mat(embs_set)\n",
        "  for idx in np.argsort(-self_sims_set, axis=None)[:num_to_show]:\n",
        "    x, y = np.unravel_index(idx, self_sims_set.shape)\n",
        "    print(self_sims_set[x][y])\n",
        "    print(ds[int(x)][\"question\"][:100])\n",
        "    print(ds[int(y)][\"question\"][:100])\n",
        "  print(\"----\")\n",
        "\n",
        "  # np.ma.indices(self_sim_mat(target_embs)"
      ],
      "metadata": {
        "id": "CAOo1z8nXjBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target_ds[63][\"question\"], target_ds[63][\"question\"]\n",
        "# np.unravel_index(, target_self_sims.shape)"
      ],
      "metadata": {
        "id": "Gfe0BeN9LGzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target_self_sims.shape"
      ],
      "metadata": {
        "id": "MFknfZxxZ_zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conduct the same two tests, but this time use the retro set itself. Effectively, we are asking two questions:\n",
        "1. How likely is it that the cosine similarities between the retro and the combined dataset were pulled from the same distribution as the cosine similarities between the combined dataset and itself?\n",
        "\n",
        "2. How likely is it that the cosine similarities between the retro dataset and itself were pulled from the same distribution as the cosine similarities between the combined dataset and itself?\n"
      ],
      "metadata": {
        "id": "cXal_x4XrXPt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Elfi8AhBDHd"
      },
      "outputs": [],
      "source": [
        "retro_stat = sp.stats.anderson_ksamp([combined_cos_sim,\n",
        "                                      np.concatenate((cross_sim_vec(target_embs, retro_embs),\n",
        "                                                      self_sim_mat(retro_embs).compressed()))]).statistic\n",
        "logfile_write(DATASET_FILENAME,f'Similarity ADk-test statistic for Retro: {retro_stat:.3f}')\n",
        "print(f'Similarity ADk-test statistic for Retro: {retro_stat:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting"
      ],
      "metadata": {
        "id": "L0BeGEaLsONZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwPQW6UvBv9F"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(11,9))\n",
        "\n",
        "# LEFT PLOT: histogram of AK(random_samples(COMBINED,len(RETRO))ðŸ –COMBINED);\n",
        "# orange line is AK(RetroðŸ –COMBINED)\n",
        "xstart = -2\n",
        "counts, bins = np.histogram(ak_stats)\n",
        "ymax = 1.02*max(counts)\n",
        "ax.stairs(counts, bins, fill=True, alpha=.6)\n",
        "ax.plot([retro_stat, retro_stat], [0, ymax])\n",
        "ax.set_xlim(xstart, max(max(ak_stats),1.05*retro_stat))\n",
        "ax.set_ylim(0, ymax)\n",
        "ax.set_xlabel('Anderson Darling k-Sample Test Statistic')\n",
        "ax.set_ylabel('Histogram Bin Count')\n",
        "ax.set_title('Similarity Histogram: Anderson Darling k-Sample')\n",
        "# ax[0].stairs(counts, bins, fill=True, alpha=.6)\n",
        "# ax[0].plot([retro_stat_cross, retro_stat_cross], [0, ymax])\n",
        "# ax[0].set_xlim(xstart, max(max(ak_stats_cross),1.05*retro_stat_cross))\n",
        "# ax[0].set_ylim(0, ymax)\n",
        "# ax[0].set_title('Cross-Similarity')\n",
        "\n",
        "# RIGHT PLOT: histogram of AK(random_samples(COMBINED,len(RETRO))ðŸ –COMBINED);\n",
        "# orange line is AK(RetroðŸ –COMBINED)\n",
        "# counts, bins = np.histogram(ak_stats_self)\n",
        "# ymax = 1.02*max(counts)\n",
        "# ax[1].stairs(counts, bins, fill=True, alpha=.6)\n",
        "# ax[1].plot([retro_stat_self, retro_stat_self], [0, ymax])\n",
        "# ax[1].set_xlim(xstart, max(max(ak_stats_self),1.05*retro_stat_self))\n",
        "# ax[1].set_ylim(0, ymax)\n",
        "# ax[1].set_title('Self-Similarity')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate final p-values"
      ],
      "metadata": {
        "id": "es4SCH5RsSqU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeE6RCKJB_oV"
      },
      "outputs": [],
      "source": [
        "# Set z-score for 99% confidence interval\n",
        "    # NOTE: this is the confidence interval on the pvalues, which is necessary\n",
        "    #   because we didn't we are sampling from the distribution instead of\n",
        "    #   knowing it explicitly\n",
        "z = 2.576\n",
        "\n",
        "# How many test statistics for cross similarity of sub-samplings of the\n",
        "#   combined dataset larger than test statistic for cross similarity of retro\n",
        "pval = (ak_stats > retro_stat).mean()\n",
        "\n",
        "# Calc confidence on self-similarity pval\n",
        "conf = z*np.sqrt((pval*(1-pval))/N)\n",
        "\n",
        "logfile_write(DATASET_FILENAME,[f'Similarity p-value: [{pval-conf:.3f},{pval+conf:.3f}]\\n',f'  ðŸ – ~{pval*100:.2f}% chance that a sample could have been pulled which results in an AK\\n\\ttest statistic that is greater than or equal to the value seen when comparing\\n\\t(cosine similarities between Combined & itself) and\\n\\t(cosine similarities between Combined & Retro).'])\n",
        "print(f'Similarity p-value: [{pval-conf:.3f},{pval+conf:.3f}]')\n",
        "print(f'  ðŸ – ~{pval*100:.2f}% chance that a sample could have been pulled which results in an AK\\n\\ttest statistic that is greater than or equal to the value seen when comparing\\n\\t(cosine similarities between Combined & itself) and\\n\\t(cosine similarities between Combined & Retro).')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity Check with Coarse Metric"
      ],
      "metadata": {
        "id": "ZU5Mdr2Zx6CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean cosine similarity value of subsets of embeddings\n",
        "    # shorthand: mean(cosine_similarity(random_samples(COMBINED,len(RETRO))))\n",
        "means = np.zeros(N,)\n",
        "for i in range(N):\n",
        "    means[i] = np.concatenate((cross_sim_vec(left_stack[i], pull_stack[i]),self_sim_mat(pull_stack[i]).compressed())).mean()\n",
        "\n",
        "retro_mean = np.concatenate((cross_sim_vec(target_embs, retro_embs),self_sim_mat(retro_embs).compressed())).mean()\n",
        "\n",
        "logfile_write(DATASET_FILENAME,[f'Mean Cosine Similarity for Retro: {retro_mean:.3f}'])\n",
        "print(f'Mean Cosine Similarity for Retro: {retro_mean:.3f}')"
      ],
      "metadata": {
        "id": "LHvShcR_p-qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set z-score for 99% confidence interval\n",
        "    # NOTE: this is the confidence interval on the pvalues, which is necessary\n",
        "    #   because we didn't we are sampling from the distribution instead of\n",
        "    #   knowing it explicitly\n",
        "z = 2.576\n",
        "\n",
        "# How many means of cosine similarities for sub-samplings of the\n",
        "#   combined dataset are larger than the mean for Retro\n",
        "pval = (means > retro_mean).mean()\n",
        "\n",
        "# Calc confidence on pval\n",
        "conf = z*np.sqrt((pval*(1-pval))/N)\n",
        "\n",
        "logfile_write(DATASET_FILENAME,[f'Similarity p-value: [{pval-conf:.3f},{pval+conf:.3f}]\\n',f'  ðŸ – ~{pval*100:.2f}% chance that a sample could have been pulled that has a mean\\n\\tcosine similarity which is greater than the mean cosine similarity of Retro.'])\n",
        "print(f'Similarity p-value: [{pval-conf:.3f},{pval+conf:.3f}]')\n",
        "print(f'  ðŸ – ~{pval*100:.2f}% chance that a sample could have been pulled that has a mean\\n\\tcosine similarity which is greater than the mean cosine similarity of Retro.')"
      ],
      "metadata": {
        "id": "W6pI6jI2wgzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(11,9))\n",
        "\n",
        "# PLOT: histogram of mean(cosine_similarity(random_samples(COMBINED,len(RETRO))));\n",
        "#    orange line is mean(cosine_similarity(Retro))\n",
        "counts, bins = np.histogram(means)\n",
        "ymax = 1.02*max(counts)\n",
        "ax.stairs(counts, bins, fill=True, alpha=.6)\n",
        "ax.plot([retro_mean, retro_mean], [0, ymax])\n",
        "ax.set_xlim(min(min(bins),retro_mean), max(max(bins),1.05*retro_mean))\n",
        "ax.set_ylim(0, ymax)\n",
        "ax.set_xlabel('Mean Cosine Similarity')\n",
        "ax.set_ylabel('Histogram Bin Count')\n",
        "ax.set_title('Similarity Histogram: Mean Cosine Similarity')\n",
        "ax.legend(['Mean cos-sim of pulls[i]', 'Mean cos-sim of Retro'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j4KoltM5rAPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "print(f'Total time: {t1-t0:.1f}')"
      ],
      "metadata": {
        "id": "pwld0aDp3XlO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}